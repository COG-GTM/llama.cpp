model:
  path: ../models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
n_ctx: 256
sampling:
  seed: 42
  temp: 0.0
prompt: "Hello from YAML"
n_predict: 16
simple_io: true
